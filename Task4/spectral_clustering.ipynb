{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import math\n",
    "from scipy.sparse import coo_matrix\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.linalg import eigs\n",
    "from scipy.sparse import identity\n",
    "from numpy import linalg\n",
    "from scipy import cluster\n",
    "from scipy.sparse import csgraph\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#User input function\n",
    "def get_parameters():\n",
    "    answer = input(\"\\nDo you want to use default parameters? y/n \")\n",
    "    \n",
    "    if answer == \"y\":\n",
    "        k = 2\n",
    "    else:\n",
    "        k = int(input(\"Number of clusters: \"))     \n",
    "    return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function used for import of data in json format\n",
    "def data_iterator(path):\n",
    "    \n",
    "    print(\"Importing data. Please wait.\\n\")\n",
    "    \n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for f in files:\n",
    "            if f.endswith('.json'):\n",
    "                fp = os.path.join(root,f)\n",
    "                with open(fp) as o:\n",
    "                    data = json.load(o)\n",
    "                yield {\"similars\" : data[\"similars\"], \"track_id\": data[\"track_id\"], \"tags\": data[\"tags\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function will return matrix W of csr format\n",
    "\n",
    "def create_weight_matrix():\n",
    "    \n",
    "    row,col,data=[],[],[]\n",
    "    pairs = set() #set of pairs of nodes (row, column) for which the edge between them exists\n",
    "    \n",
    "    tmp = dict()\n",
    "    \n",
    "    per_row = dict()\n",
    "\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        #row will be index of the song S\n",
    "        if track_id[i] not in nodes:\n",
    "            all_songs.append(track_id[i])\n",
    "            nodes[track_id[i]] = len(nodes)\n",
    "        \n",
    "        r = nodes[track_id[i]]\n",
    "\n",
    "        #now indices of similar songs are needed\n",
    "        for j in range(len(similars[i])):\n",
    "            similar_song = similars[i][j][0] #similar song\n",
    "            weight = similars[i][j][1] #weight\n",
    "            \n",
    "            #column will be index of the song which is similar to S\n",
    "            if similar_song not in nodes:\n",
    "                nodes[similar_song] = len(nodes)\n",
    "                all_songs.append(similar_song)\n",
    "            c = nodes[similar_song]\n",
    "\n",
    "            pair = (r,c)\n",
    "            sim = (c,r)\n",
    "            \n",
    "            if pair not in tmp:\n",
    "                tmp[pair] = weight\n",
    "                tmp[sim] = weight\n",
    "            else:\n",
    "                current_weight = tmp[pair]\n",
    "                if weight > current_weight:\n",
    "                    tmp[pair] = weight\n",
    "                    tmp[sim] = weight\n",
    "\n",
    "    for pair in tmp:\n",
    "        row.append(pair[0])\n",
    "        col.append(pair[1])\n",
    "        data.append(tmp[pair])\n",
    "                        \n",
    "    # calculate the graph adjacency matrix as a coo_matrix\n",
    "    N = len(nodes)\n",
    "    A = scipy.sparse.coo_matrix((data,(row,col)),shape=(N,N))\n",
    "    \n",
    "    #convert to csr_matrix\n",
    "    A = scipy.sparse.csr_matrix(A)\n",
    "    \n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#LAPLACIAN\n",
    "def create_laplacian_matrix(W, n = False):\n",
    "    \n",
    "    if n == False:\n",
    "        L = csgraph.laplacian(W, normed=False)\n",
    "    else:\n",
    "        L = csgraph.laplacian(W, normed=True)\n",
    "    \n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def spectral_clustering(lap, k = 2):\n",
    "\n",
    "    vals, vecs = scipy.sparse.linalg.eigsh(lap,lap.shape[0]-1)\n",
    "    \n",
    "    if k == 2:\n",
    "        eig_space = vecs[:,0]\n",
    "    elif k == 3:\n",
    "        eig_space = vecs[:,[0,1]]\n",
    "    elif k == 4:\n",
    "        eig_space = vecs[:,[0,1,2]]\n",
    "    else:\n",
    "        eig_space = vecs[:,[0,1,2,3]]\n",
    "\n",
    "    c,labels = scipy.cluster.vq.kmeans2(eig_space, k)\n",
    "\n",
    "    clusters = dict()\n",
    "    \n",
    "    for i,c in enumerate(labels):\n",
    "        if c not in clusters:\n",
    "            clusters[c] = []\n",
    "\n",
    "        clusters[c].append(i)\n",
    "        \n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_items(s):\n",
    "    s_coo = s.tocoo()\n",
    "    return set(zip(s_coo.row, s_coo.col))\n",
    "\n",
    "def get_ratio_cut(W, clusters):\n",
    "    cut = 0\n",
    "    #for c in range(len(clusters)):\n",
    "    for m in range(0,len(clusters)-1):   \n",
    "        for n in range(m+1, len(clusters)):\n",
    "            for i in clusters[m]:\n",
    "                for j in clusters[n]:\n",
    "                    if ((i,j) in get_items(W)) == True:\n",
    "                        cut += W[i,j]\n",
    "                        \n",
    "    return cut\n",
    "\n",
    "def get_min_cut(W):\n",
    "\n",
    "    mincut = math.inf\n",
    "\n",
    "    permutations = itertools.permutations(nodes)\n",
    "    \n",
    "    for p in permutations:\n",
    "        ar = np.array(p)\n",
    "        for i in range(1,len(ar)):\n",
    "            clusters2 = dict()\n",
    "            clusters2[0] = np.array(range(0,i))\n",
    "            clusters2[1] = np.array(range(i,len(ar)-1))\n",
    "            cut = get_ratio_cut(W, clusters2)\n",
    "            #print(clusters2[0],clusters2[1],cut)\n",
    "            if cut != 0 and cut < mincut:\n",
    "                mincut = cut\n",
    "                \n",
    "    return mincut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insert path to dataset: C:\\Users\\Maki\\Desktop\\testset\n",
      "Importing data. Please wait.\n",
      "\n",
      "Results of clustering: \n",
      "To cluster number 0 belong following songs:\n",
      "['JAGODA', 'LUBENICA']\n",
      "To cluster number 1 belong following songs:\n",
      "['KRUSKA', 'JABUKA', 'SLJIVA']\n",
      "---------------------\n",
      "Min cut:  0.5\n",
      "Min cut hard assignment:  0.2\n"
     ]
    }
   ],
   "source": [
    "path = input(\"Insert path to dataset: \")\n",
    "df = pd.DataFrame(data_iterator(path))\n",
    "#GLOBAL VARIABLES:\n",
    "nodes = dict()\n",
    "tags_unique = dict()\n",
    "all_songs = []\n",
    "track_id = df[\"track_id\"]\n",
    "similars = df[\"similars\"]\n",
    "tags = df[\"tags\"]\n",
    "\n",
    "W = create_weight_matrix()\n",
    "\n",
    "L = create_laplacian_matrix(W)\n",
    "\n",
    "clusters = spectral_clustering(L, 2)\n",
    "\n",
    "print(\"Results of clustering: \")\n",
    "\n",
    "for i in range(len(clusters)):\n",
    "    print(\"To cluster number\",i,\"belong following songs:\")\n",
    "    sngs = []\n",
    "    for j in clusters[i]:\n",
    "        sngs.append(all_songs[j])\n",
    "    print(sngs)\n",
    "\n",
    "print(\"---------------------\")\n",
    "print(\"Min cut: \", get_min_cut(W))\n",
    "\n",
    "print (\"Min cut hard assignment: \",get_ratio_cut(W, clusters))\n",
    "\n",
    "#clusters"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
