{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#IMPORTS\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "import pandas as pd\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import scipy\n",
    "import random\n",
    "from scipy.sparse.linalg import svds\n",
    "from sklearn import linear_model\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#COLD START ISSUE AVOIDING\n",
    "#Function cold_start iteratively deletes all users and songs that have <= 5 (<=eps) appearences\n",
    "def cold_start(matrix, all_users, all_songs, eps = 5):\n",
    "\n",
    "    iterations = 0\n",
    "\n",
    "    while 1:\n",
    "        \n",
    "        if iterations == 20:\n",
    "            break\n",
    "        \n",
    "        changed = False\n",
    "        \n",
    "        removed_users = set()\n",
    "        removed_songs = set()\n",
    "\n",
    "        for s in all_songs:\n",
    "            count = 0 #count a song's appearences\n",
    "\n",
    "            potential_users = set()\n",
    "\n",
    "            for u in all_users:\n",
    "                if u in matrix:\n",
    "                    if s in matrix[u]:\n",
    "                        count += 1\n",
    "                        potential_users.add(u)\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "                if count > eps: #already has more than 5 appearences\n",
    "                    break\n",
    "\n",
    "            if count <= eps: #need to delete the song from all user's dictionaries\n",
    "\n",
    "                for u in potential_users:\n",
    "                    if u in matrix:\n",
    "                        matrix[u].pop(s)\n",
    "\n",
    "                changed = True\n",
    "\n",
    "                removed_songs.add(s)\n",
    "\n",
    "\n",
    "        for u in all_users:\n",
    "            if u in matrix:\n",
    "                if len(matrix[u]) <= eps:\n",
    "                    removed_users.add(u)\n",
    "                    if u in matrix:\n",
    "                        matrix.pop(u) \n",
    "                    changed = True\n",
    "\n",
    "        for s in removed_songs:\n",
    "            all_songs.remove(s)\n",
    "\n",
    "        for u in removed_users:\n",
    "            all_users.discard(u)\n",
    "        \n",
    "        iterations += 1\n",
    "\n",
    "        if changed == False:  \n",
    "            break\n",
    "        \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#The function hash_count is used for calculating the bucket to whom the count_play belongs\n",
    "def hash_count(n, b):\n",
    "    largest = int(math.log(n, 2)) #largest power of two < n\n",
    "    if largest < b:\n",
    "        return largest+1\n",
    "    else:\n",
    "        return b\n",
    "\n",
    "#The function preprocess_data reads data from the file and creates dictionary of dictionaries\n",
    "#which means for each user creates dictionary of the songs that he played with corresponding count of plays\n",
    "def preprocess_data(path = \"train_triplets.txt\", n = 300000, b = 10):\n",
    "\n",
    "    data_tmp = pd.read_table(path, \n",
    "                             usecols=[0, 1, 2], \n",
    "                             names=['user', 'song', 'plays'],\n",
    "                             nrows=n)\n",
    "\n",
    "\n",
    "    songs = np.unique(data_tmp['song'])\n",
    "    users = np.unique(data_tmp['user'])\n",
    "\n",
    "    #matrix is in the format of dictionary of dictionaries and it contains only positive values\n",
    "    matrix = collections.defaultdict(lambda: collections.defaultdict(int))\n",
    "\n",
    "    #convert table to matrix\n",
    "    data = data_tmp.as_matrix()  \n",
    "\n",
    "    #add data in the new matrix \n",
    "    for triple in range(0,n):\n",
    "        user = data[triple][0]\n",
    "        song = data[triple][1]\n",
    "        matrix[user][song] += data[triple][2]\n",
    "\n",
    "    #BINNING\n",
    "    all_keys = set(matrix.keys())\n",
    "\n",
    "    for key in all_keys:\n",
    "        songs_of_user = set(matrix[key].keys())\n",
    "        for s in songs_of_user:\n",
    "            play_count = matrix[key][s] \n",
    "            matrix[key][s] = hash_count(play_count, b)\n",
    "       \n",
    "            \n",
    "    #COLD START ISSUE AVOIDING\n",
    "    matrix = cold_start(matrix, set(users), set(songs))\n",
    "    \n",
    "    return matrix\n",
    "        \n",
    " \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function optimaze use alternationg optimization algorithm for the Latent Factors Method\n",
    "def optimize(M, k = 30):\n",
    "\n",
    "    #initilize P i Q using SVD\n",
    "    U, s, V = svds(M, k=k)\n",
    "    S = np.diag(s)\n",
    "    Q = U.dot(S)\n",
    "    P = V\n",
    "\n",
    "    reg = linear_model.Ridge (alpha=1.0, fit_intercept=False)\n",
    "\n",
    "    for q in range(15):\n",
    "        #FIXED Q\n",
    "        for i in range(len(M[0])): #for each user\n",
    "            idx = np.flatnonzero(M[:,i]) \n",
    "            if len(idx) > 0:\n",
    "                Mi = M[:,i][idx]\n",
    "                Qi = Q[idx,]\n",
    "                reg.fit(Qi, Mi)\n",
    "                P[:,i] = reg.coef_\n",
    "        \n",
    "        #FIXED P\n",
    "        for i in range(len(M)): #for each movie\n",
    "            idx = np.flatnonzero(M[i]) \n",
    "            if len(idx) > 0:\n",
    "                Mi = M[i][idx]\n",
    "                Pi = (P.transpose())[idx,]\n",
    "                reg.fit(Pi, Mi)\n",
    "                Q[i] = reg.coef_\n",
    "                \n",
    "    return P,Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TEST SET\n",
    "#For the matrix M which is the only parameter for the function, test set that contains 200 random values from M is created\n",
    "#Test set consists of triples (row, column, value)\n",
    "#Chosen values are removed from the matrix M\n",
    "def create_test_set(M):\n",
    "\n",
    "    test_set = set()\n",
    "    indices = np.where(M>0)\n",
    "    random_ind = random.sample(range(len(indices[0])),  200) \n",
    "    for x in random_ind:\n",
    "        row = indices[0][x]\n",
    "        column = indices[1][x]\n",
    "        test_set.add((row, column, M[row][column]))\n",
    "        M[row][column] = 0\n",
    "        \n",
    "    return (M, test_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This function is used for the calculation of root-mean-square error (RMSE). \n",
    "#The RMSE represents the sample standard deviation of the differences between predicted values and real(observed) values. \n",
    "#RMSE is calculated fot the dataset which consists of triples (row, column, value)\n",
    "def calculate_rmse(P, Q, test_set):\n",
    "\n",
    "    prediction_matrix = np.dot(Q, P)\n",
    "\n",
    "    numerator = 0\n",
    "\n",
    "    for triple in test_set:\n",
    "        real_value = triple[2]\n",
    "        predicted_value =  prediction_matrix[triple[0]][triple[1]]\n",
    "        numerator += (predicted_value - real_value)**2\n",
    "    \n",
    "    return math.sqrt(numerator / len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want to use default parameters? y/n  n\n",
      "How many rows do you want? n = 300000\n",
      "How many bins do you want to be used? b = 10\n",
      "What is the value of k? k = 30\n",
      "What is the path for the dataset? path = C:\\\\Users\\\\Maki\\\\Desktop\\\\MMDS\\\\train_triplets\\\\train_triplets.txt\n",
      "\n",
      "The preprocessing has just started. Please be patient.\n",
      "\n",
      "Preprocessing has been completed. Dimensions of matrix M:  5693 x 10966\n",
      "\n",
      "Preprocessing time:   218.0\n",
      "\n",
      "The test set has been created.\n",
      "-------------------------------------------------------\n",
      "\n",
      "The optimization has just started. Please be patient.\n",
      "\n",
      "Optimization time:   135.747\n",
      "-------------------------------------------------------\n",
      "\n",
      "RMSE =  1.19\n",
      "\n",
      "-------------------------------------------------------\n",
      "Thank you for using our program\n"
     ]
    }
   ],
   "source": [
    "while(1):\n",
    "    answer = input('Do you want to use default parameters? y/n  ')\n",
    "\n",
    "    if answer == 'y':\n",
    "        print ('Default parameters: n = 300000, b = 10, k = 30, dataset_path =  train_triplets.txt')\n",
    "        n = 300000\n",
    "        b = 10\n",
    "        k = 30\n",
    "        path = \"train_triplets.txt\"\n",
    "        #path = \"C:\\\\Users\\\\Maki\\\\Desktop\\\\MMDS\\\\train_triplets\\\\train_triplets.txt\"\n",
    "    elif answer == 'n':\n",
    "        n = int(input('How many rows do you want? n = '))\n",
    "        b = int(input('How many bins do you want to be used? b = '))\n",
    "        k = int(input('What is the value of k? k = '))\n",
    "        path = input('What is the path for the dataset? path = ')\n",
    "\n",
    "    else:\n",
    "        print('ERROR: Wrong input!')\n",
    "        continue\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    print('\\nThe preprocessing has just started. Please be patient.')\n",
    "\n",
    "    matrix = preprocess_data(path, n, b)\n",
    "\n",
    "    if len(matrix) == 0:\n",
    "        print('All data deleted')\n",
    "        continue\n",
    "\n",
    "    #converting dictionary to matrix format\n",
    "    df = pd.DataFrame(matrix).T.fillna(0)\n",
    "    M = df.as_matrix()\n",
    "        \n",
    "    print('\\nPreprocessing has been completed. Dimensions of matrix M: ',len(M),'x',len(M[0]))\n",
    "    print('\\nPreprocessing time:  ', round(time.time() - start_time ,3))\n",
    "    \n",
    "    #test set\n",
    "    (M, test_set) = create_test_set(M)  \n",
    "    print('\\nThe test set has been created.')\n",
    "    print('-------------------------------------------------------')\n",
    "\n",
    "    #optimization\n",
    "    print('\\nThe optimization has just started. Please be patient.')\n",
    "    start_time = time.time()\n",
    "    (P, Q) = optimize(M, k)\n",
    "    print('\\nOptimization time:  ', round(time.time() - start_time ,3))\n",
    "    print('-------------------------------------------------------')\n",
    "\n",
    "    #RMSE calculation\n",
    "    rmse = calculate_rmse(P, Q, test_set)\n",
    "    print ('\\nRMSE = ', round(rmse,2))     \n",
    "    \n",
    "    print ('\\n-------------------------------------------------------')\n",
    "    print ('Thank you for using our program')     \n",
    "    break\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
